f
# sapply and lapply
sapply (1:5 , function(i) {
mean(runif(10 , min = i, max = i + 1))
})
lapply (1:5 , function(i) {
mean(runif(10 , min = i, max = i + 1))
})
?CO2
head(CO2)
is.data.frame(CO2)
CO2$Plant
CO2$Type
CO2$Treatment
CO2$conc
CO2$uptake
# Extract the update values for which Plant equals Qn1
CO2$uptake[CO2$Plant == "Qn1"]
# Extract the update values for which Plant equals Qn1 and Type equals Quebec. Also calculate the mean
CO2$uptake[(CO2$Plant == "Qn1") & (CO2$Type == "Quebec")]
mean(CO2$uptake[(CO2$Plant == "Qn1") & (CO2$Type == "Quebec")])
# Calculate how many uptake values are there which are less than 25
sum(ifelse(CO2$uptake <= 25, 1, 0))
# For loop
count1 = NULL
for(k in 1:length(CO2$uptake)) {
if(CO2$Treatment[k] == "chilled" & CO2$uptake[k] <= 25) {
count1[k] = 1
} else {
count1[k] = 0
}
}
sum(count1)
# While loop
k = 1
count2 = NULL
while (k <= length(CO2$uptake)) {
if(CO2$Treatment[k] == "chilled" & CO2$uptake[k] <= 25) {
count2[k] = 1
} else {
count2[k] = 0
}
k = k + 1
}
sum(count2)
# Calculate the average distance taken to stop given the speed of the cars using lapply and sapply
speed = unique(cars$speed)
lapply(1:length(speed), function(h){
x = mean(cars$dist[cars$speed == speed[h]])
return(x)
})
speed = unique(cars$speed)
sapply(1:length(speed), function(h){
y = mean(cars$dist[cars$speed == speed[h]])
return(y)
})
# Writing simple functions
average.sd = function(n) {
# Check if n >= 10
if(n >= 10) {
x = sample(1:n, size = 10, replace = FALSE)
} else{
# if false generate error message
stop("Enter number more than 10")
}
# Calculate mean and standard deviation
y1 = mean(x)
y2 = var(x)
y = c(y1, y2)
return(y) # Return statement
}
average.sd(4) # Function calls
average.sd(11)
average.sd(20)
# Function body
f = function(x) {
return(x^2 - 3*x + 4)
}
# Generate x values to evaluate the function
xval = seq(0, 1, length = 20)
yval = f(x = xval) # Function call
# Plot the curve
plot(xval, yval, type = "l", xlab = "x", ylab = "f(x)")
# Data Visualization
# Scatter Plot
x = cars$speed
y = cars$dist
plot(x, y, col = "maroon", pch = 16, xlab = "speed", ylab = "distance",
main = "Scatter Plot of distance vs speed")
library (ggplot2)
ggplot(cars, aes(x = speed, y = dist)) + geom_point () + ggtitle (" Scatter Plot of distance vs speed ")
# Line diagram
ggplot(cars, aes(x = speed, y = dist)) + geom_line() + ggtitle("Line Diagram of distance vs speed")
# Bar Plot
# Calculate the average mpg values corresponding
# to each cylinder value
# Three categories
mpg1 = mean(mtcars$mpg[mtcars$cyl == 4])
mpg2 = mean(mtcars$mpg[mtcars$cyl == 6])
mpg3 = mean(mtcars$mpg[mtcars$cyl == 8])
barplot(c(mpg1, mpg2, mpg3) ~ c(4, 6, 8),
xlab = "mtcars$cyl",
ylab = "average mpg per cyl",
ylim = c(0, 28),
col = "maroon",  # color of the bars
width = c(5, 5, 5),  # width of the bars
space = 2, # bar spacing
main = "Barplot for average mpg vs cyl")
cyl = c(4, 6, 8)
avg.mpg = c(mpg1, mpg2, mpg3)
data = data.frame(cyl, avg.mpg)
ggplot(data, aes(y = avg.mpg , x = cyl)) +
geom_bar(position = "dodge", stat="identity") +
ggtitle("Barplot for average mpg vs cyl for mtcars") +
ylim(c(0, 28))
# Divided Bar Diagram
mpg1 = mean(mtcars$mpg[mtcars$cyl == 4])
mpg2 = mean(mtcars$mpg[mtcars$cyl == 6])
mpg3 = mean(mtcars$mpg[mtcars$cyl == 8])
disp1 = mean(mtcars$disp[mtcars$cyl == 4])
disp2 = mean(mtcars$disp[mtcars$cyl == 6])
disp3 = mean(mtcars$disp[mtcars$cyl == 8])
hp1 = mean(mtcars$hp[mtcars$cyl == 4])
hp2 = mean(mtcars$hp[mtcars$cyl == 6])
hp3 = mean(mtcars$hp[mtcars$cyl == 8])
qsec1 = mean(mtcars$qsec[mtcars$cyl == 4])
qsec2 = mean(mtcars$qsec[mtcars$cyl == 6])
qsec3 = mean(mtcars$qsec[mtcars$cyl == 8])
cyl = c(4, 6, 8)
avg.mpg = c(mpg1, mpg2, mpg3)
avg.disp = c(disp1, disp2, disp3)
avg.hp = c(hp1, hp2, hp3)
avg.qsec = c(qsec1, qsec2, qsec3)
mtcars.mat = rbind(avg.mpg, avg.disp, avg.hp, avg.qsec)
colnames(mtcars.mat) = c("4", "6", "8")
barplot(mtcars.mat,
col = c("skyblue", "deepskyblue2", "dodgerblue4", "blue"),
ylim = c(0, 650),
legend.text = rownames(mtcars.mat),
args.legend = list(x = "topleft"),
main = "Divided Barplot for mtcars")
# Multiple Bar Diagram
barplot(mtcars.mat,
col = c("skyblue", "deepskyblue2", "dodgerblue4", "blue"),
ylim = c(0, 350),
legend.text = rownames(mtcars.mat),
args.legend = list(x = "topleft"),
main = "Multiple Bardiagram for mtcars",
beside = TRUE)
# Pie Diagram
# Calculating averages
food.tobacco = mean(USPersonalExpenditure[1, ])
house.opr = mean(USPersonalExpenditure[2, ])
med.health = mean(USPersonalExpenditure[3, ])
per.care = mean(USPersonalExpenditure[4, ])
prvt.edu = mean(USPersonalExpenditure[5, ])
# Pie diagram
avg.exp = c(food.tobacco, house.opr, med.health, per.care, prvt.edu)
categories = c("food.tobacco", "household.operation", "medical.health", "personal.care", "private.education")
pie(avg.exp, labels = categories, main = "Average personal expenditures over years")
# Box plot
boxplot(mtcars$hp ~ as.factor(mtcars$cyl), col = "skyblue",
xlab = "Cylinders",
ylab = "Horse Power",
main = "Boxplot for hp by cyl for mtcars")
# Histogram
hist(faithful$eruptions, freq = FALSE,
xlab = "Eruption time",
main = "Histogram for eruptions data")
pie(avg.exp, labels = categories, main = "Average personal expenditures over years")
locs=matrix(1:5,ncol=1);vecchia_specify(locs,m=2)
library(GPvecchia)
locs=matrix(1:5,ncol=1);vecchia_specify(locs,m=2)
v=vecchia_specify(locs,m=2)
str(v)
library(spatstat)
setwd("~/research/sketching/paper/figures")
# SURFACE PLOTS USING MBA PACKAGE
library(MBA)
library(fields)
setwd("~/research/nldn")
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
summary(bei)
class(bei)
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(9, 10, 1:8)]
head(df)
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
head(df)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
newdf <- as.ppp(df, owin = (latWin, lonWin))
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
newdf <- as.ppp(newdf, owin = (latWin, lonWin))
latWin
newdf <- as.ppp(newdf, W = (latWin, lonWin))
newdf <- as.ppp(newdf, owin(latWin, lonWin))
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
newdf <- as.ppp(df, owin(latWin, lonWin))
class(newdf)
head(newdf)
head(df)
# Get rid of unnecessary columns
df <- df[ , c(1, 2, 4, 6, 9)]
head(df)
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
head(df)
# Get rid of unnecessary columns
df <- df[ , c(1, 2, 6, 9)]
head(df)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
newdf <- as.ppp(df, owin(latWin, lonWin))
# EDA
plot(newdf)
plot(df$LON, df$LAT)
# Basic model
fit <- ppm(newdf ~ 1)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
head(df)
# Get rid of unnecessary columns
df <- df[ , c(1, 2)]
head(df)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
# Create ppp object
newdf <- as.ppp(df, owin(latWin, lonWin))
# EDA
plot(newdf)
# Basic model
fit <- ppm(newdf ~ 1)
summary(fit)
exp(3.61887)
# Tinkering with the spatstat package
library(spatstat)
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
head(df)
# Get rid of unnecessary columns
df <- df[ , c(1, 2, 6)]
head(df)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
# Create ppp object
newdf <- as.ppp(df, owin(latWin, lonWin))
head(newdf)
# Basic model
fit <- ppm(newdf ~ 1, Poisson())
lansing
marks
lansing$marks
ppm(lans ~ marks, Poisson())
ppm(lansing ~ marks, Poisson())
ppm(lansing ~ marks, Poisson())
head(newdf)
head(newdf$marks)
head(as.data.frame(newdf))
head(df)
ppm(newdf ~ marks, Poisson())
ppm(lansing ~ marks, Poisson())
ppm(newdf ~ marks, Poisson())
class(lansing)
class(newdf)
lansing
newdf
df <- read.csv("daily_data/2010/07/01.csv")
head(df)
# Move latitude and longitude to be first columns
df <- df[ , c(10, 11, 1:9)]
head(df)
# Get rid of unnecessary columns
df <- df[ , c(1, 2, 6)]
df$DETECTOR_QUANTITY <- as.factor(df$DETECTOR_QUANTITY)
head(df)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
head(df)
class(df$DETECTOR_QUANTITY)
# What is the window?
latWin <- c(min(df$LAT), max(df$LAT))
lonWin <- c(min(df$LON), max(df$LON))
# Create ppp object
newdf <- as.ppp(df, owin(latWin, lonWin))
# EDA
plot(newdf)
# Basic model
fit <- ppm(newdf ~ 1, Poisson())
summary(fit)
# Marked model
ppm(newdf ~ marks, Poisson())
setwd("~/research/storm_surges")
readRDS("results/flood_results_sketching.RDS")$acc
sketching <- readRDS("results/flood_results_sketching.RDS")
sketching$means
sketching$predictions
dim(sketching$predictions)
sketching$predictions[,1:5]
mean(sketching$predictions[3,] - sketching$predictions[1,])
sketching <- readRDS("results/flood_results_sketching.RDS")
subdomains <- readRDS("results/flood_results_subdomains.RDS")
stratified <- readRDS("results/flood_results_stratified.RDS")
mean(sketching$predictions[3,] - sketching$predictions[1,])
mean(subdomains$predictions[3,] - subdomains$predictions[1,])
mean(stratified$predictions[3,] - stratified$predictions[1,])
data_split <- readRDS("results/data_split.RDS")
data_split
data_split[[1]]
str(data_split)
load("data/flood_data.RData")
dim(out)
trueTest <- out[1, indexTest]
indexTest <- data_split[[2]]
load("data/flood_data.RData")
trueTest <- out[1, indexTest]
truTest
trueTest
length(trueTest)
# Coverage
mean(sketching$predictions[3,] > trueTest & sketching$predictions[1,] < trueTest)
# Coverage
mean(sketching$predictions[3,] > trueTest & sketching$predictions[1,] < trueTest)
mean(subdomains$predictions[3,] > trueTest & subdomains$predictions[1,] < trueTest)
mean(stratified$predictions[3,] > trueTest & stratified$predictions[1,] < trueTest)
setwd("~/research/storm_surges")
sk <- readRDS("results/flood_results_sketching.RDS")
sk <- readRDS("results/flood_results_sketching.RDS")
su <- readRDS("results/flood_results_subdomains.RDS")
st <- readRDS("results/flood_results_stratified.RDS")
sk$predictions
dim(sk$predictions)
i=1
obj <- readRDS(paste0("results/sketching/flood_rep", i, ".RDS"))
dim(obj$predSamples)
ind <- (1 + 200*(i-1)):(1 + 200*i)
ind
i=2
ind <- (1 + 200*(i-1)):(1 + 200*i)
ind
ind <- (1 + 200*(i-1)):(200*i)
ind
preds <- matrix(0, nrow = 2486, ncol = 2000)
for (i in 1:10) {
ind <- (1 + 200*(i-1)):(200*i)
preds[ , ind] <- readRDS(paste0("results/sketching/flood_rep", i, ".RDS"))$predSamples
}
dim(preds)
plot.ts(preds[1,])
plot.ts(preds[1,1:200])
abline(h = mean(preds[1,]))
D <- matrix(1:4, 2, 2)
D
exp(-0.1*D)
exp(-D)
exp(-5*D)
exp(-3*D)
j <- 2
plot.ts(preds[j,1:200])
abline(h = mean(preds[j,]))
plot.ts(preds[1,1:200])
abline(h = mean(preds[1,1:200]))
var(preds[1,1:200])
var(preds[1,201:400])
var(preds[1,401:600])
var(preds[1,601:800])
var(preds[1,801:1000])
var(preds[1,1801:2000])
plot.ts(preds[1,1801:2000])
seq(0.1, 0.5, length=10)
setwd("~/research/storm_surges")
preds <- matrix(0, nrow = 2486, ncol = 2000)
for (i in 1:10) {
ind <- (1 + 200*(i-1)):(200*i)
preds[ , ind] <- readRDS(paste0("results/sketching/flood_rep", i, ".RDS"))$predSamples
}
dim(preds)
plot.ts(preds[1,1801:2000])
abline(h = mean(preds[1,1:200]))
var(preds[1,1:200])
var(preds[1,201:400])
var(preds[1,401:600])
var(preds[1,601:800])
var(preds[1,801:1000])
var(preds[1,1801:2000])
quantile(preds[1,1801:2000], .025)
quantile(preds[1,1801:2000], .975)
quantile(preds[1,1801:2000], c(0.1, 0.9))
quantile(preds[1,1801:2000], c(0.1, 0.9))*3.1
# SOURCES
source("mcmc_functions/flood_mcmc.R") # Metropolis-Gibbs Sampler
source("mcmc_functions/priors.R")
source("mcmc_functions/jacobians.R")
source("mcmc_functions/likelihood.R")
source("mcmc_functions/posterior.R")
source("other_functions/parallel_functions.R") # Parallel wrapper functions
source("other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
# Libraries
library(parallel) # For parallel computation
library(doParallel) # For parallel computation
library(foreach) # For parallel computation
library(mvtnorm)
library(fields)
library(MBA)
library(anticlust) # for balanced clustering
library(splitTools) # for stratified splitting
# Read in
load("data/flood_data.RData")
mySeed <- 123
# Randomly sample indices for train and test data
nObs <- nrow(coords)
pctTrain <- 0.95
n <- nTrain <- floor(pctTrain * nObs)
nTest <- ceiling((1 - pctTrain) * nObs)
set.seed(mySeed)
indexTrain <- sort(sample(1:nObs, nTrain))
indexTest <- sort(setdiff(1:nObs, indexTrain))
STest <- as.matrix(coords[indexTest, 1:2])
dim(STest)
S <- STest[1:100,]
D <- rdist(S)
dim(D)
D[1:5,1:5]
exp(-2*D[1:5,1:5])
exp(-6*D[1:5,1:5])
exp(-100*D[1:5,1:5])
library(Matrix)
library(GPvecchia)
library(Matrix)
library(fields)
set.seed(1988)
spatial.dim=2
n=50
if(spatial.dim==1){
locs=matrix(runif(n),ncol=1)
} else {
locs <- cbind(runif(n),runif(n))
}
beta=2
sig2=1; range=.1; smooth=1.5
covparms =c(sig2,range,smooth)
covfun <- function(locs) sig2*MaternFun(fields::rdist(locs),covparms)
nuggets=rep(.1,n)
Om0 <- covfun(locs)+diag(nuggets)
z=as.numeric(t(chol(Om0))%*%rnorm(n))
data=z+beta
# plot simulated data
if(spatial.dim==1) {
plot(locs,data)
} else {
fields::quilt.plot(locs,data, nx=n, ny=n)
}
n.p=100
if(spatial.dim==1){  #  1-D case
locs.pred=matrix(seq(0,1,length=n.p),ncol=1)
} else {   # 2-D case
grid.oneside=seq(0,1,length=round(sqrt(n.p)))
locs.pred=as.matrix(expand.grid(grid.oneside,grid.oneside)) # grid of pred.locs
}
n.p=nrow(locs.pred)
vecchia.est=vecchia_estimate(data,locs,,output.level=0)
preds=vecchia_pred(vecchia.est,locs.pred)
##  exact prediction
mu.exact=as.numeric(covfun(rbind(locs,locs.pred))[,1:n]%*%solve(Om0,data-beta))+beta
cov.exact=covfun(rbind(locs,locs.pred))-
covfun(rbind(locs,locs.pred))[,1:n]%*%solve(Om0,t(covfun(rbind(locs,locs.pred))[,1:n]))
var.exact=diag(cov.exact)
cov.exact.pred=cov.exact[n+(1:n.p),n+(1:n.p)]
### plot Vecchia and exact predictions
if(spatial.dim==1) {
plot(locs,z)
lines(locs.pred,preds$mean.pred,col='blue')
lines(locs.pred,preds$mean.pred-1.96*sqrt(preds$var.pred),col='blue',lty=2)
lines(locs.pred,preds$mean.pred+1.96*sqrt(preds$var.pred),col='blue',lty=2)
lines(locs.pred,mu.exact[n+(1:n.p)],col='red')
lines(locs.pred,mu.exact[n+(1:n.p)]-1.96*sqrt(var.exact[n+(1:n.p)]),col='red',lty=2)
lines(locs.pred,mu.exact[n+(1:n.p)]+1.96*sqrt(var.exact[n+(1:n.p)]),col='red',lty=2)
} else {
sdrange=range(sqrt(c(preds$var.pred,var.exact[n+(1:n.p)])))
defpar = par(mfrow=c(2,3))
fields::quilt.plot(locs,z, nx=sqrt(n.p), ny=sqrt(n.p))
fields::quilt.plot(locs.pred,preds$mean.pred, nx=sqrt(n.p), ny=sqrt(n.p))
fields::quilt.plot(locs.pred,sqrt(preds$var.pred),zlim=sdrange, nx=sqrt(n.p), ny=sqrt(n.p))
fields::quilt.plot(locs,z, nx=sqrt(n.p), ny=sqrt(n.p))
fields::quilt.plot(locs.pred,mu.exact[n+(1:n.p)], nx=sqrt(n.p), ny=sqrt(n.p))
fields::quilt.plot(locs.pred,sqrt(var.exact[n+(1:n.p)]),zlim=sdrange, nx=sqrt(n.p), ny=sqrt(n.p))
par(defpar)
}
dim(locs)
dim(locs.pred)

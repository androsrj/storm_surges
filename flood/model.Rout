
R version 4.2.0 (2022-04-22) -- "Vigorous Calisthenics"
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # Clear environment and free unused memory
> rm(list = ls())
> gc()
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 273690 14.7     660857 35.3   451905 24.2
Vcells 459126  3.6    8388608 64.0  1800280 13.8
> 
> # SOURCES
> source("../mcmc_functions/mcmc.R") # Metropolis-Gibbs Sampler
> source("../mcmc_functions/priors.R")
> source("../mcmc_functions/jacobians.R")
> source("../mcmc_functions/likelihood.R")
> source("../mcmc_functions/posterior.R")
> source("../other_functions/parallel_functions.R") # Parallel wrapper functions
> source("../other_functions/helper_functions.R") # Other misc functions (not part of MCMC)
> 
> # Libraries
> library(parallel) # For parallel computation
> library(doParallel) # For parallel computation
Loading required package: foreach
Loading required package: iterators
> library(foreach) # For parallel computation
> library(mvtnorm)
> library(fields)
Loading required package: spam
Spam version 2.9-1 (2022-08-07) is loaded.
Type 'help( Spam)' or 'demo( spam)' for a short introduction 
and overview of this package.
Help for individual functions is also obtained by adding the
suffix '.spam' to the function name, e.g. 'help( chol.spam)'.

Attaching package: ‘spam’

The following objects are masked from ‘package:mvtnorm’:

    rmvnorm, rmvt

The following objects are masked from ‘package:base’:

    backsolve, forwardsolve

Loading required package: viridis
Loading required package: viridisLite

Try help(fields) to get started.
> library(MBA)
> library(anticlust) # for balanced clustering
> library(splitTools) # for stratified splitting
> 
> # Read in
> load("data/flood_data.RData")
> 
> # Clusters and seed
> nCores <- 2
> totalCores <- 10
> mySeed <- 123
> 
> # Randomly sample indices for train and test data
> nObs <- nrow(coords)
> pctTrain <- 0.95
> n <- nTrain <- floor(pctTrain * nObs)
> nTest <- ceiling((1 - pctTrain) * nObs)
> set.seed(mySeed)
> indexTrain <- sort(sample(1:nObs, nTrain))
> indexTest <- sort(setdiff(1:nObs, indexTrain))
> saveRDS(list(indexTrain, indexTest), "results/data_split.RDS")
> 
> # Divide using train and test indices
> storms <- 1:50
> Y <- lapply(storms, \(i) out[i, indexTrain])
> X <- lapply(storms, \(i) {
+   Xintercept <- rep(1, nTrain)
+   Xstorm <- matrix(rep(unlist(inputs[i, ]), nTrain), ncol = 5, byrow = TRUE)
+   Xelev <- coords$elev_meters[indexTrain]
+   X <- cbind(Xintercept, Xstorm, Xelev)
+   colnames(X) <- c("int", colnames(inputs), "elev")
+   return(X)
+ })
> S <- as.matrix(coords[indexTrain, 1:2])
> D <- rdist(S)
> 
> YTest <- lapply(storms, \(i) out[i, indexTest])
> XTest <- lapply(storms, \(i) {
+   Xintercept <- rep(1, nTest)
+   Xstorm <- matrix(rep(unlist(inputs[i, ]), nTest), ncol = 5, byrow = TRUE)
+   Xelev <- coords$elev_meters[indexTest]
+   X <- cbind(Xintercept, Xstorm, Xelev)
+   colnames(X) <- c("int", colnames(inputs), "elev")
+   return(X)
+ })
> STest <- as.matrix(coords[indexTest, 1:2])
> DTest <- rdist(STest)
> 
> 
> # Sketching
> thetaVals <- seq(10, 100, length = totalCores)
> model <- "full_gp"
> mProp <- 0.01
> nSubj <- length(storms)
> test_subj <- 1
> 
> cl <- makeCluster(nCores)
> registerDoParallel(cl)
> strt <- Sys.time()
> set.seed(mySeed)
> obj <- foreach(i = 1:totalCores, .packages = "mvtnorm") %dopar% sketching_parallel(i)  
> final.time <- Sys.time() - strt 
> stopCluster(cl)
> if (file.exists(".RData")) {
+   file.remove(".RData")
+ }
> gc()
             used    (Mb) gc trigger    (Mb)   max used    (Mb)
Ncells    1965125   105.0    3754454   200.6    2715527   145.1
Vcells 2459548579 18764.9 3533919970 26961.7 2462214139 18785.3
> flood_results_sketching <- wasserstein(nChains = totalCores, 
+                                        method = "sketching", 
+                                        model = "full_gp", 
+                                        splitType = NULL, 
+                                        time = final.time)
> saveRDS(flood_results_sketching, paste0("results/flood_results_sketching.RDS"))
> 
> 
> 
> 
> 
> 
> 
> 
> 
> # D&C, subdomain split
> #indexSubd <- balanced_clustering(STrain, totalCores)
> #subsetsX <- lapply(1:totalCores, function(k) { 
> #  lapply(storms, function(s) XTrain[[s]][which(indexSubd == k), ])
> #  })
> #subsetsY <- lapply(1:totalCores, function(k) { 
> #  lapply(storms, function(s) YTrain[[s]][which(indexSubd == k)])
> #})
> #subsetsD <- lapply(1:totalCores, function(k) DTrain[which(indexSubd == k), which(indexSubd == k)])
> #
> #cl <- makeCluster(nCores)
> #registerDoParallel(cl)
> #strt <- Sys.time()
> #set.seed(mySeed)
> #obj <- foreach(i = 1:totalCores, .packages = "mvtnorm") %dopar% subdomains_parallel(i)  
> #final.time <- Sys.time() - strt 
> #stopCluster(cl)
> #if (file.exists(".RData")) {
> #  file.remove(".RData")
> #}
> #gc()
> #flood_results_subdomains <- wasserstein(nChains = totalCores, method = "subdomains")
> #saveRDS(flood_results_subdomains, paste0("results/flood_results_subdomains.RDS"))
> 
> 
> 
> # D&C, stratified split
> #indexStrat <- list2Vec(partition(indexSubd, p = rep(1/nCores, totalCores)))
> #subsetsX <- lapply(1:totalCores, function(k) { 
> #  lapply(storms, function(s) XTrain[[s]][which(indexStrat == k), ])
> #})
> #subsetsY <- lapply(1:totalCores, function(k) { 
> #  lapply(storms, function(s) YTrain[[s]][which(indexStrat == k)])
> #})
> #subsetsD <- lapply(1:totalCores, function(k) DTrain[which(indexStrat == k), which(indexStrat == k)])
> #
> #cl <- makeCluster(nCores)
> #registerDoParallel(cl)
> #strt <- Sys.time()
> #set.seed(mySeed)
> #obj <- foreach(i = 1:totalCores, .packages = "mvtnorm") %dopar% stratified_parallel(i)  
> #final.time <- Sys.time() - strt 
> #stopCluster(cl)
> #if (file.exists(".RData")) {
> #  file.remove(".RData")
> #}
> #gc()
> #flood_results_stratified <- wasserstein(nChains = totalCores, method = "stratified")
> #saveRDS(flood_results_stratified, paste0("results/flood_results_stratified.RDS"))
> 
> 
> 
> proc.time()
     user    system   elapsed 
   66.219    20.843 42422.628 
